# -*- coding: utf-8 -*-
"""i170321_hafsaSaqib_A.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yMxwWzEZ6DVli1P3sGcWk1Bc66sUuWKU
"""

!pip install ktrain
!pip install transformers

import ktrain
import random 
import pickle
import torch
import time
import transformers
import tensorflow as tf
import pandas as pd
import numpy as np
import tensorflow.keras.utils as ku
import torch.nn as nn

from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
from ktrain import text
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from transformers import AutoModel, BertTokenizerFast
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
from google.colab import drive

device = torch.device("cuda")

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

drive.mount('/content/drive', force_remount=True)

trf = '/content/drive/MyDrive/ALL data/train.csv'
train_data = pd.read_csv(trf)
tf = '/content/drive/MyDrive/ALL data/test.csv'
test_data = pd.read_csv(tf)
vf = '/content/drive/MyDrive/ALL data/dev.csv'
valid_data = pd.read_csv(vf)

train_data

test_data

validation_data

correct_statement= []
incorrect_statement=[]
right_reason1= []
right_reason2 = []

for i in range(len(train_data['Correct Statement'])):
  correct_statement.append([train_data.iloc[i,0], 1])
  incorrect_statement.append([train_data.iloc[i,1], 0])
  right_reason1.append([train_data.iloc[i,2], 1])
  right_reason2.append([train_data.iloc[i,3], 1])

for i in range(len(test_data['Correct Statement'])):
  correct_statement.append([test_data.iloc[i,0], 1])
  incorrect_statement.append([test_data.iloc[i,1], 0])
  right_reason1.append([test_data.iloc[i,2], 1])
  right_reason2.append([test_data.iloc[i,3], 1])

for i in range(len(validation_data['Correct Statement'])):
  correct_statement.append([validation_data.iloc[i,0], 1])
  incorrect_statement.append([validation_data.iloc[i,1], 0])
  right_reason1.append([validation_data.iloc[i,2], 1])
  right_reason2.append([validation_data.iloc[i,3], 1])

data_list = corr_statement + incorr_statement + right_reason1 + right_reason2
random.shuffle(data_list) 
data_list

test_list = corr_statement + incorr_statement + right_reason1 + right_reason2
random.shuffle(test_list) 
test_list

validation_list = corr_statement + incorr_statement + right_reason1 + right_reason2
random.shuffle(validation_list) 
validation_list

column_labels = ['Sentence', 'Labels']
train_data_df = pd.DataFrame(data_list, columns = column_labels)
test_data_df = pd.DataFrame(test_list, columns = column_labels)
dev_data_df = pd.DataFrame(validation_list, columns = column_labels)

train_data_df.head()

(X_train, Y_train) , (X_test, Y_test), preprocess = text.texts_from_df(train_df= train_data_df, 
                                                                       text_column= 'Sentence', 
                                                                       label_columns= 'Labels',
                                                                       val_df = dev_data_df,
                                                                       maxlen = 400,
                                                                       preprocess_mode = 'bert')

X_train[0].shape

model = text.text_classifier(name='bert', 
                             train_data = (X_train, Y_train),
                             preproc = preprocess)

learner = ktrain.get_learner(model = model,
                             train_data = (X_train, Y_train),
                             val_data = (X_test, Y_test),
                             batch_size = 6)

learner.fit_onecycle(lr = 2e-5, epochs=1)

predictor = ktrain.get_predictor(learner.model, preprocess)

predictor.save('/content/drive/My Drive/bert')

result = predictor.predict(list(test_data_df['Sentence']))
result

for i in range(len(result)):
  if result[i] == 'Labels':
    result[i] = 1
  else:
    result[i] = 0

result

test_data_df

count=0
for i in range (len(result)):
  if result[i] == test_data_df.iloc[i,1]:
    count+=1
accuracy_test = (count/len(result)) * 100
print("Accuracy on Test Dataset: ", accuracy_test, "%")

predictor_load = ktrain.load_predictor('/content/drive/MyDrive/bert')

t_f = '/content/drive/MyDrive/ALL data/Test Data/subtaskA_test_data.csv'
test_data = pd.read_csv(t_f)

result = predictor.predict(list(test_data['sent1']))
for i in range(len(result)):
  if result[i] == 'Labels':
    result[i] = 1
  else:
    result[i] = 0
result

len(result)

t_ids = list(test_data['id'])
len(t_ids)

t_list = []
for i in range(len(result)):
  t_list.append([t_ids[i],result[i]])
t_list

test_data = pd.DataFrame(t_list)

gfg_csv_data = test_data.to_csv('subtaskA_answers.csv', index = True)